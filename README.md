# Fintech UX Challenge Week 2 - 10 Academy

## ğŸ—‚ Challenge Context
This repository documents the submission for 10 Academyâ€™s **B5W2: Customer Experience Analytics for Fintech Apps** challenge. The objective is to evaluate customer satisfaction with mobile banking apps by scraping, analyzing, and visualizing user reviews from the Google Play Store for:

- Commercial Bank of Ethiopia (CBE)
- Bank of Abyssinia (BOA)
- Dashen Bank

This project simulates the role of a data analyst at Omega Consultancy, advising fintechs on improving user experience and retention.

The project includes:

- ğŸ§¹ Clean scraping and preprocessing of Play Store reviews  

- ğŸ’¬ Sentiment analysis (VADER, DistilBERT) and keyword clustering  

- ğŸ“Š UX pain point detection and feature insight generation  

- ğŸ›¢ï¸ Relational database setup using Oracle XE  

- ğŸ“ˆ Stakeholder-ready visualizations and diagnostics

- âœ… **Streamlit App** for a seamless, non-technical user experience  


## ğŸ”§ Project Setup

To reproduce this environment:

1. Clone the repository:

```bash
git clone https://github.com/NabloP/b5w2-customer-ux-analytics-challenge.git
cd b5w2-customer-ux-analytics-challenge
```

2. Create and activate a virtual environment:
   
**On Windows:**
    
```bash
python -m venv customer-ux-challenge
.\customer-ux-challenge\Scripts\Activate.ps1
```

**On macOS/Linux:**

```bash
python3 -m venv customer-ux-challenge
source customer-ux-challenge/bin/activate
```

3. Install dependencies

```bash
pip install -r requirements.txt
```

## âš™ï¸ CI/CD (GitHub Actions)

This project uses GitHub Actions for Continuous Integration. On every `push` or `pull_request` event, the following workflow is triggered:

- Checkout repo

- Set up Python 3.10

- Install dependencies from `requirements.txt`

CI workflow is defined at:

    `.github/workflows/unittests.yml`

## ğŸ“ Project Structure

<!-- TREE START -->
ğŸ“ Project Structure

solar-challenge-week1/
â”œâ”€â”€ LICENSE
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â”œâ”€â”€ unittests.yml
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ cleaned/
â”‚   â”‚   â”œâ”€â”€ reviews_all_banks_20250607_140803_cleaned.csv
â”‚   â”‚   â”œâ”€â”€ reviews_all_banks_20250607_141201_cleaned.csv
â”‚   â”‚   â”œâ”€â”€ reviews_all_banks_cleaned.csv
â”‚   â”œâ”€â”€ outputs/
â”‚   â””â”€â”€ raw/
â”‚       â”œâ”€â”€ reviews_BOA_20250607_124729.csv
â”‚       â”œâ”€â”€ reviews_CBE_20250607_124725.csv
â”‚       â”œâ”€â”€ reviews_Dashen_20250607_124733.csv
â”‚       â”œâ”€â”€ reviews_all_banks.csv
â”‚       â”œâ”€â”€ reviews_all_banks_20250607_140803.csv
â”‚       â”œâ”€â”€ reviews_all_banks_20250607_141201.csv
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ task-1-scraping-preprocessing.ipynb
â”‚   â”œâ”€â”€ task-2-sentiment-thematic-analysis.ipynb
â”‚   â”œâ”€â”€ task-3-oracle-storage.ipynb
â”‚   â”œâ”€â”€ task-4-insights-visuals.ipynb
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ cleaning_runner.py
â”‚   â”œâ”€â”€ generate_tree.py
â”‚   â”œâ”€â”€ oracle_insert.py
â”‚   â”œâ”€â”€ run_streamlit.py
â”‚   â”œâ”€â”€ scraping_runner.py
â”‚   â”œâ”€â”€ sentiment_pipeline.py
â”‚   â”œâ”€â”€ visualize_insights.py
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ cleaning/
â”‚   â”‚   â”œâ”€â”€ review_cleaner.py
â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â”œâ”€â”€ oracle_connector.py
â”‚   â”œâ”€â”€ nlp/
â”‚   â”‚   â”œâ”€â”€ keyword_theme_extractor.py
â”‚   â”‚   â”œâ”€â”€ sentiment_classifier.py
â”‚   â”œâ”€â”€ scraper/
â”‚   â”‚   â”œâ”€â”€ review_scraper.py
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ preprocessing.py
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â””â”€â”€ ui/
    â”œâ”€â”€ app_streamlit.py
<!-- TREE END -->


## âœ… Status

- â˜‘ï¸ Task 1 complete: scraping and cleaning pipeline finalized

- â˜‘ï¸ Streamlit UI for end-to-end data collection and preprocessing

- â˜‘ï¸ Modular architecture for reuse in scripts and notebooks

- â˜‘ï¸ Row diagnostics and metadata tracking implemented

- â˜‘ï¸ Ready for Task 2: Sentiment & Thematic NLP Pipeline


## ğŸ“¦ What's in This Repo

This repository is structured to maximize modularity, reusability, and clarity:

- ğŸ“ Scaffolded directory layout for pipelines, UIs, and NLP modules
- ğŸ’» Streamlit UI for scraping and cleaning with per-bank selection, export toggles, and file previews
- ğŸ§ª CI/CD automation via GitHub Actions for reproducibility
- ğŸ§¹ Auto-updating README structure using generate_tree.py
- ğŸ“š Notebook-first development with clean progression through all tasks
This repository documents the Week 1 challenge for 10 Academyâ€™s AI Mastery Bootcamp. It includes:

- ğŸ“ **Scaffolded directory structure** using best practices for `src/`, `notebooks/`, `scripts/`, and `tests/`

- ğŸ’» Streamlit UI for scraping and cleaning with per-bank selection, export toggles, and file previews

- ğŸ§ª **CI/CD integration** via GitHub Actions for reproducibility and reliability

- ğŸ§¹ **README auto-updating** via `scripts/generate_tree.py` to keep documentation aligned with project layout

- ğŸ“š Notebook-first development with clean progression through all tasks

- ğŸ“Š Modular EDA workflows for review cleaning, UX issue detection, and app-specific user sentiment

- ğŸ“š **Clear Git hygiene** (no committed `.venv` or `.csv`), commit messages and pull request usage

- ğŸ§  **My Contributions:** All project scaffolding, README setup, automation scripts, and CI configuration were done from scratch by me


## ğŸ§ª Usage

### ğŸ›ï¸ Option 1: Using the Streamlit App

The Streamlit UI (`ui/app_streamlit.py`) provides an interactive interface to perform both review scraping and cleaning with no code required.

**To launch the app locally:**
```bash
streamlit run ui/app_streamlit.py
```

**ğŸ§© Streamlit Features:**

- Scrape Google Play reviews for CBE, BOA, or Dashen

- Export reviews per-bank or as a combined dataset

- Preview scraped files in-app

- Clean any raw file from `data/raw/`

- View sidebar diagnostics for:

    - Missing fields dropped

    - Blank reviews removed

    - Duplicate `reviewIds` filtered

- Download cleaned outputs directly

All exports are timestamped and saved to `data/raw/` or `data/cleaned/` depending on context.


### ğŸ Option 2: Using Python Scripts
For automated, reproducible runs from the command line or notebooks, use the modular runners in the `scripts/` folder.

**ğŸ”¹ Scraping Reviews**
To scrape reviews from one or more banks and export to CSV:

```python
 scripts/scraping_runner.py --bank CBE --num_reviews 100
 ```

Options:

- `--bank`: one of `CBE`, `BOA`, `Dashen`, or `all`

- `--num_reviews`: maximum number of reviews per app


**ğŸ”¹ Cleaning Reviews**
To clean a raw file and export the cleaned result:

```python 
scripts/cleaning_runner.py --input_file data/raw/reviews_BOA_20250607_124729.csv
```

This removes:

- Rows with missing fields

- Blank or whitespace-only reviews

- Duplicate entries by `reviewId`

Cleaned files are saved under `data/cleaned/`.

### ğŸ” How It Works Internally

Both the Streamlit app and script-based runners share the same core logic, implemented in the following modules:

- `src/scraper/review_scraper.py` â€“ Fetches reviews from the Play Store

- `src/cleaning/review_cleaner.py` â€“ Cleans and validates reviews

- `src/utils/preprocessing.py` â€“ Shared text preprocessing functions

- `scripts/run_streamlit.py` â€“ Optional wrapper for launching UI from CLI

- `scripts/generate_tree.py` â€“ Auto-generates folder tree for `README.md`

Each module is written using object-oriented principles and is fully reusable across CLI, notebook, and UI contexts.


## ğŸ§  Design Philosophy
This project was developed with a focus on:

- âœ… Modular Python design using classes, helper modules, and runners (clean script folders and testable code)
- âœ… High commenting density to meet AI and human readability expectations
- âœ… Clarity (in folder structure, README, and docstrings)
- âœ… Reproducibility through consistent Git hygiene and generate_tree.py
- âœ… Rubric-alignment (clear deliverables, EDA, and insights)

## ğŸš€ Author
Nabil Mohamed
AIM Bootcamp Participant
GitHub: [NabloP](https://github.com/NabloP)