{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b188ff04",
   "metadata": {},
   "source": [
    "# üìä Task 2 ‚Äì Sentiment & Thematic Analysis  \n",
    "üìò Version: 2025-06-08\n",
    "\n",
    "Quantify user sentiment and identify key themes in cleaned Google Play reviews for three Ethiopian banks (CBE, BOA, Dashen) to uncover satisfaction drivers and pain points.\n",
    "\n",
    "### This notebook covers:\n",
    "- Loading pre-cleaned reviews (`data/cleaned/reviews_all_banks_cleaned.csv`)\n",
    "- Computing review-level sentiment scores and labels (VADER, with optional DistilBERT/FinBERT fallback)\n",
    "- Aggregating mean sentiment by bank and star-rating\n",
    "- Extracting significant keywords & phrases (TF-IDF unigrams/bigrams, spaCy noun chunks)\n",
    "- Assigning reviews to 3‚Äì5 rule-based themes per bank (e.g., Account Access, Transaction Performance, UI/UX)\n",
    "- Exporting an enriched CSV (`data/outputs/reviews_with_sentiment_themes.csv`) for reporting and visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "720a56ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Changed working directory to project root\n",
      "‚úÖ Added to sys.path: c:\\Users\\admin\\Documents\\GIT Repositories\\b5w2-customer-ux-analytics-challenge\n",
      "üìÅ Output path ready\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# üõ† Ensure Notebook Runs from Project Root (for src/ imports to work)\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# If running from /notebooks/, move up to project root\n",
    "if os.path.basename(os.getcwd()) == \"notebooks\":\n",
    "    os.chdir(\"..\")\n",
    "    print(\"üìÇ Changed working directory to project root\")\n",
    "\n",
    "# Add project root to sys.path so `src/` modules can be imported\n",
    "project_root = os.getcwd()\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "    print(f\"‚úÖ Added to sys.path: {project_root}\")\n",
    "\n",
    "# Optional: verify file presence to confirm we're in the right place\n",
    "expected_path = \"data/raw\"\n",
    "print(\n",
    "    \"üìÅ Output path ready\"\n",
    "    if os.path.exists(expected_path)\n",
    "    else f\"‚ö†Ô∏è Output path not found: {expected_path}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93b11e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# üì¶ Core Libraries\n",
    "# ------------------------------------------------------------------------------\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# üß† NLP & Text Processing (Task 2)\n",
    "# ------------------------------------------------------------------------------\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Sentiment analysis\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# Optional: transformer-based sentiment\n",
    "# from transformers import pipeline\n",
    "\n",
    "# SymSpell for spelling correction (if you re‚Äênormalize in‚Äêpipeline)\n",
    "from symspellpy.symspellpy import SymSpell\n",
    "\n",
    "# spaCy for noun‚Äêchunk/theme extraction (if needed)\n",
    "import spacy\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# üîß Display & Config\n",
    "# ------------------------------------------------------------------------------\n",
    "from IPython.display import display\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# ‚öôÔ∏è Optional: Download NLTK resources if running for first time\n",
    "# ------------------------------------------------------------------------------\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6e979b",
   "metadata": {},
   "source": [
    "## üì• Load Cleaned Google Play Reviews Dataset\n",
    "\n",
    "This step initializes the core reviews dataset used throughout the sentiment & thematic analysis pipeline:\n",
    "\n",
    "- Loads `reviews_all_banks_cleaned.csv` from the `data/cleaned/` directory.  \n",
    "- Automatically parses the `date` column (UTC) into datetime objects.  \n",
    "- Wraps `pandas.read_csv()` in a fault-tolerant `ReviewDataLoader` class with UTF-8 ‚Üí latin1 fallback.  \n",
    "- Includes verbose diagnostics to confirm encoding, row/column counts, and schema.  \n",
    "\n",
    "This ensures a reliable, reproducible foundation for all downstream sentiment scoring and theme extraction tasks.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d56781e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÑ File loaded: data/cleaned/reviews_all_banks_cleaned.csv\n",
      "üì¶ Encoding used: utf-8\n",
      "üî¢ Shape: 1,200 rows √ó 12 columns\n",
      "üß™ Columns: review, rating, date, bank, source, reviewId, userName, userImage, appVersion, repliedAt, replyContent, thumbsUpCount\n",
      "\n",
      "‚úÖ Successfully loaded 1,200 cleaned reviews into `df_reviews`\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# üì• Load Cleaned Google Play Reviews Dataset\n",
    "# ------------------------------------------------------------------------------\n",
    "from src.nlp.review_loader import ReviewDataLoader\n",
    "\n",
    "DATA_PATH = \"data/cleaned/reviews_all_banks_cleaned.csv\"\n",
    "\n",
    "try:\n",
    "    loader = ReviewDataLoader(path=DATA_PATH, verbose=True)\n",
    "    df_reviews = loader.load()\n",
    "    print(\n",
    "        f\"‚úÖ Successfully loaded {len(df_reviews):,} cleaned reviews into `df_reviews`\"\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to load reviews dataset: {e}\")\n",
    "    df_reviews = pd.DataFrame()  # gracefully degrade for further diagnosis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65029f22",
   "metadata": {},
   "source": [
    "## üîÑ Normalize Review Text & Split per Bank\n",
    "\n",
    "This step applies our Tier-1 `TextNormalizer` to standardize raw review content and prepares bank-specific datasets for targeted analysis:\n",
    "\n",
    "- Instantiates `TextNormalizer` (SymSpell + spaCy) with defensive checks  \n",
    "- Detects the source text column (`corrected_review` if present, otherwise `review`)  \n",
    "- Normalizes each review into a new `normalized_review` column, with per-row error logging  \n",
    "- Splits the normalized DataFrame into `df_combined` plus `df_cbe`, `df_boa`, and `df_dashen`  \n",
    "- Prints review-count diagnostics for each bank to confirm correct partitioning  \n",
    "\n",
    "This ensures you have uniformly cleaned, lemmatized, and spell-corrected text ready for downstream sentiment scoring and theme extraction.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b16e902",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\Documents\\GIT Repositories\\b5w2-customer-ux-analytics-challenge\\src\\nlp\\text_normalizer.py:23: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources  # To locate symspell dictionaries\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß TextNormalizer initialized successfully\n",
      "‚ÑπÔ∏è Normalizing text from column: `review`\n",
      "‚è±Ô∏è Normalized 500 reviews so far\n",
      "‚è±Ô∏è Normalized 1,000 reviews so far\n",
      "‚úÖ Completed normalization for 1,200 reviews\n",
      "üìä Review counts by bank:\n",
      "  ‚Ä¢ CBE:    400\n",
      "  ‚Ä¢ BOA:    400\n",
      "  ‚Ä¢ Dashen: 400\n",
      "  ‚Ä¢ TOTAL:  1,200\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# üîÑ Normalize Review Text & Split per Bank (Robust Column Handling)\n",
    "# ------------------------------------------------------------------------------\n",
    "from src.nlp.text_normalizer import TextNormalizer\n",
    "\n",
    "# 1Ô∏è‚É£ Instantiate the normalizer\n",
    "try:\n",
    "    normalizer = TextNormalizer(use_symspell=True, use_spacy=True)\n",
    "    print(\"üîß TextNormalizer initialized successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to initialize TextNormalizer: {e}\")\n",
    "    raise\n",
    "\n",
    "# 2Ô∏è‚É£ Determine which text column to normalize\n",
    "if \"corrected_review\" in df_reviews.columns:\n",
    "    source_col = \"corrected_review\"\n",
    "elif \"review\" in df_reviews.columns:\n",
    "    source_col = \"review\"\n",
    "else:\n",
    "    raise KeyError(\n",
    "        \"‚ö†Ô∏è Neither 'corrected_review' nor 'review' column found in df_reviews\"\n",
    "    )\n",
    "\n",
    "print(f\"‚ÑπÔ∏è Normalizing text from column: `{source_col}`\")\n",
    "\n",
    "# 3Ô∏è‚É£ Apply normalization with per-row error handling\n",
    "normalized_texts = []\n",
    "for idx, text in enumerate(df_reviews[source_col].astype(str), start=1):\n",
    "    try:\n",
    "        normalized = normalizer.normalize(text)\n",
    "    except Exception as ex:\n",
    "        print(f\"‚ö†Ô∏è Normalization error at row {idx}: {ex}\")\n",
    "        normalized = \"\"  # fallback\n",
    "    normalized_texts.append(normalized)\n",
    "    if idx % 500 == 0:\n",
    "        print(f\"‚è±Ô∏è Normalized {idx:,} reviews so far\")\n",
    "\n",
    "# 4Ô∏è‚É£ Assign the normalized column\n",
    "df_reviews[\"normalized_review\"] = normalized_texts\n",
    "print(f\"‚úÖ Completed normalization for {len(df_reviews):,} reviews\")\n",
    "\n",
    "# 5Ô∏è‚É£ Split into per-bank DataFrames\n",
    "df_combined = df_reviews.copy()  # full dataset\n",
    "df_cbe = df_reviews[df_reviews[\"bank\"] == \"CBE\"].reset_index(drop=True)\n",
    "df_boa = df_reviews[df_reviews[\"bank\"] == \"BOA\"].reset_index(drop=True)\n",
    "df_dashen = df_reviews[df_reviews[\"bank\"] == \"Dashen\"].reset_index(drop=True)\n",
    "\n",
    "# 6Ô∏è‚É£ Verify split counts\n",
    "print(\n",
    "    f\"üìä Review counts by bank:\\n\"\n",
    "    f\"  ‚Ä¢ CBE:    {len(df_cbe):,}\\n\"\n",
    "    f\"  ‚Ä¢ BOA:    {len(df_boa):,}\\n\"\n",
    "    f\"  ‚Ä¢ Dashen: {len(df_dashen):,}\\n\"\n",
    "    f\"  ‚Ä¢ TOTAL:  {len(df_combined):,}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df3bb73",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "sentiment_classifier.py ‚Äì Ensemble Sentiment Analysis Module (B5W2)\n",
    "--------------------------------------------------------------------\n",
    "Combines DistilBERT, VADER, and TextBlob into an equal-weight ensemble for robust review sentiment scoring.\n",
    "Implements star-rating rules with expanded allowances for 4‚òÖ‚Äì5‚òÖ, computes uncertainty, and flags significant mismatches.\n",
    "\n",
    "Responsibilities:\n",
    "- Load local DistilBERT SST-2 model (PyTorch) via `AutoTokenizer` & `AutoModelForSequenceClassification`\n",
    "- Compute signed sentiment scores in [-1, +1] from:\n",
    "    ‚Ä¢ DistilBERT (P_pos ‚Äì P_neg)\n",
    "    ‚Ä¢ VADER compound\n",
    "    ‚Ä¢ TextBlob polarity\n",
    "- Build an **equal-weight** ensemble score and discrete label (¬±0.05 thresholds)\n",
    "- Calculate **uncertainty** as the standard deviation of the three scorers\n",
    "- Apply **rating-based rules**:\n",
    "    ‚Ä¢ ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ/‚òÖ‚òÖ‚òÖ‚òÖ ‚Üí allow any label (positive, neutral, negative)  \n",
    "    ‚Ä¢ ‚òÖ‚òÖ‚òÖ        ‚Üí allow any label  \n",
    "    ‚Ä¢ ‚òÖ‚òÖ         ‚Üí neutral or negative  \n",
    "    ‚Ä¢ ‚òÖ          ‚Üí negative only\n",
    "- **Flag** reviews where the ensemble label is disallowed by the rating and the ensemble score deviates from the rule label by >0.5\n",
    "- Expose `run(df, text_col=\"normalized_review\")` to augment a DataFrame with:\n",
    "    ['bert','vader','textblob','ensemble','label','uncertainty','rule_label','flag']\n",
    "\n",
    "Author: Nabil Mohamed\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47460d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\Documents\\GIT Repositories\\b5w2-customer-ux-analytics-challenge\\customer-ux-challenge\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\admin\\Documents\\GIT Repositories\\b5w2-customer-ux-analytics-challenge\\customer-ux-challenge\\Lib\\site-packages\\transformers\\utils\\generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "c:\\Users\\admin\\Documents\\GIT Repositories\\b5w2-customer-ux-analytics-challenge\\customer-ux-challenge\\Lib\\site-packages\\transformers\\utils\\generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "c:\\Users\\admin\\Documents\\GIT Repositories\\b5w2-customer-ux-analytics-challenge\\customer-ux-challenge\\Lib\\site-packages\\transformers\\utils\\generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Loaded DistilBERT model from `models/distilbert-base-uncased-finetuned-sst-2-english`\n",
      "‚úÖ Ensemble sentiment computed for 1,200 reviews\n",
      "üìä Enriched review counts by bank:\n",
      "  ‚Ä¢ CBE:    400\n",
      "  ‚Ä¢ BOA:    400\n",
      "  ‚Ä¢ Dashen: 400\n",
      "  ‚Ä¢ TOTAL:  1,200\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# üìù Sentiment Ensembling on Combined Data (Local Model Path)\n",
    "# ------------------------------------------------------------------------------\n",
    "from src.nlp.sentiment_classifier import SentimentEnsembler\n",
    "\n",
    "# Path to your local DistilBERT SST-2 model files\n",
    "MODEL_DIR = \"models/distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "\n",
    "# 1Ô∏è‚É£ Instantiate the ensembler and load models from disk\n",
    "ensembler = SentimentEnsembler(model_path=MODEL_DIR, device=\"cpu\")\n",
    "ensembler.tokenizer = ensembler.tokenizer.from_pretrained(\n",
    "    MODEL_DIR, local_files_only=True\n",
    ")\n",
    "ensembler.model = ensembler.model.from_pretrained(MODEL_DIR, local_files_only=True).to(\n",
    "    ensembler.device\n",
    ")\n",
    "print(f\"üîß Loaded DistilBERT model from `{MODEL_DIR}`\")\n",
    "\n",
    "# 2Ô∏è‚É£ Run ensemble sentiment on the combined DataFrame\n",
    "df_enriched = ensembler.run(df_combined, text_col=\"normalized_review\")\n",
    "print(f\"‚úÖ Ensemble sentiment computed for {len(df_enriched):,} reviews\")\n",
    "\n",
    "# 3Ô∏è‚É£ Split enriched DataFrame into per-bank subsets\n",
    "df_cbe = df_enriched[df_enriched[\"bank\"] == \"CBE\"].reset_index(drop=True)\n",
    "df_boa = df_enriched[df_enriched[\"bank\"] == \"BOA\"].reset_index(drop=True)\n",
    "df_dashen = df_enriched[df_enriched[\"bank\"] == \"Dashen\"].reset_index(drop=True)\n",
    "\n",
    "# 4Ô∏è‚É£ Confirm the splits\n",
    "print(\n",
    "    f\"üìä Enriched review counts by bank:\\n\"\n",
    "    f\"  ‚Ä¢ CBE:    {len(df_cbe):,}\\n\"\n",
    "    f\"  ‚Ä¢ BOA:    {len(df_boa):,}\\n\"\n",
    "    f\"  ‚Ä¢ Dashen: {len(df_dashen):,}\\n\"\n",
    "    f\"  ‚Ä¢ TOTAL:  {len(df_enriched):,}\"\n",
    ")\n",
    "\n",
    "# 5Ô∏è‚É£ (Optional) Save enriched results\n",
    "df_enriched.to_csv(\"data/outputs/reviews_enriched_all.csv\", index=False)\n",
    "# df_cbe.to_csv(\"data/outputs/reviews_enriched_cbe.csv\", index=False)\n",
    "# df_boa.to_csv(\"data/outputs/reviews_enriched_boa.csv\", index=False)\n",
    "# df_dashen.to_csv(\"data/outputs/reviews_enriched_dashen.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acae88af",
   "metadata": {},
   "source": [
    "## üì¶ Keyword, Key Phrase & Theme Extraction Module\n",
    "\n",
    "This module provides three reusable, object-oriented classes to support thematic analysis of normalized reviews:\n",
    "\n",
    "1. **KeywordExtractor**  \n",
    "   - Uses TF-IDF (unigrams + bigrams) to surface the top-N keywords across a corpus  \n",
    "   - Accepts a custom stopword list for domain-specific filtering  \n",
    "\n",
    "2. **KeyPhraseExtractor**  \n",
    "   - Leverages spaCy‚Äôs noun-chunk parser (full pipeline with dependency parsing)  \n",
    "   - Extracts and cleans key phrases, removing stopwords and non-alphanumeric noise  \n",
    "   - Aggregates across documents to return the top-N most frequent noun-phrases  \n",
    "\n",
    "3. **ThemeExtractor**  \n",
    "   - Applies rule-based theme tagging using per-bank seed keyword maps  \n",
    "   - Supports an expanded set of themes (e.g. Concise Feedback, Connectivity Issues, Functionality, Usability, Performance, Security, Notifications, Stability & Bugs, etc.)  \n",
    "   - Tags each review with one or more themes, defaulting to ‚ÄúOther‚Äù when no seeds match  \n",
    "\n",
    "**Usage:**  \n",
    "- Instantiate each extractor with your custom stopwords and seed maps  \n",
    "- Call `extract_keywords(texts)` or `extract_top_phrases(texts)` for global or per-bank analysis  \n",
    "- Use `ThemeExtractor.tag_corpus(df)` to add a `themes` column to your enriched review DataFrame  \n",
    "\n",
    "This design ensures modular, testable, and scalable extraction of keywords, key phrases, and actionable themes for your Task 2 pipeline.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f995f6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ COMBINED_STOPWORDS length: 207\n",
      "‚úÖ Loaded classes: <class 'src.nlp.keyword_theme_extractor.KeywordExtractor'> <class 'src.nlp.keyword_theme_extractor.KeyPhraseExtractor'> <class 'src.nlp.keyword_theme_extractor.ThemeExtractor'>\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# üõ† Reload and Import Keyword, Keyphrase & Theme Extractors\n",
    "# ------------------------------------------------------------------------------\n",
    "import importlib\n",
    "\n",
    "# Import your modules\n",
    "import src.nlp.stopwords as sw_module\n",
    "import src.nlp.keyword_theme_extractor as kte_module\n",
    "\n",
    "# Force-reload so notebook picks up any recent edits\n",
    "importlib.reload(sw_module)\n",
    "importlib.reload(kte_module)\n",
    "\n",
    "# Bring the classes into the notebook namespace\n",
    "KeywordExtractor = kte_module.KeywordExtractor\n",
    "KeyPhraseExtractor = kte_module.KeyPhraseExtractor\n",
    "ThemeExtractor = kte_module.ThemeExtractor\n",
    "\n",
    "# Verify that everything is in place\n",
    "print(\"‚úÖ COMBINED_STOPWORDS length:\", len(sw_module.COMBINED_STOPWORDS))\n",
    "print(\"‚úÖ Loaded classes:\", KeywordExtractor, KeyPhraseExtractor, ThemeExtractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "589b1c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîë Global Top 30 TF-IDF Keywords:\n",
      "['amazing', 'bad', 'banking', 'dash', 'dash super', 'developer', 'easy', 'easy use', 'excellent', 'experience', 'fast', 'feature', 'fix', 'good', 'great', 'like', 'money', 'need', 'nice', 'option', 'super', 'thank', 'time', 'transaction', 'transfer', 'update', 'use', 'user', 'work', 'wow'] \n",
      "\n",
      "üß† Global Top 20 Noun Phrases:\n",
      "['work', 'money', 'boa', 'love', 'transaction', 'developer option', 'life', 'easy use', 'improvement', 'good job', 'time', 'tel birr mesa', 'use', 'crash', 'screenshot', 'waw', 'payment', 'good', 'big problem', 'good easy use'] \n",
      "\n",
      "üìä Global Theme Distribution:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "themes",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "d21bd85e-fd60-42a6-954b-de514418e2ca",
       "rows": [
        [
         "Other",
         "655"
        ],
        [
         "Concise Feedback",
         "354"
        ],
        [
         "Performance",
         "103"
        ],
        [
         "Functionality",
         "78"
        ],
        [
         "Stability & Bugs",
         "34"
        ],
        [
         "Security & Trust",
         "28"
        ],
        [
         "Account Access",
         "24"
        ],
        [
         "Feature Requests",
         "22"
        ],
        [
         "Connection Issues",
         "12"
        ],
        [
         "Usability",
         "3"
        ],
        [
         "Notifications",
         "3"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 11
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>themes</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Concise Feedback</th>\n",
       "      <td>354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Performance</th>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Functionality</th>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stability &amp; Bugs</th>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Security &amp; Trust</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Account Access</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature Requests</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Connection Issues</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Usability</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Notifications</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   count\n",
       "themes                  \n",
       "Other                655\n",
       "Concise Feedback     354\n",
       "Performance          103\n",
       "Functionality         78\n",
       "Stability & Bugs      34\n",
       "Security & Trust      28\n",
       "Account Access        24\n",
       "Feature Requests      22\n",
       "Connection Issues     12\n",
       "Usability              3\n",
       "Notifications          3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved enriched themes to data/outputs/reviews_with_sentiment_themes.csv\n",
      "\n",
      "üè¶ CBE Top 30 TF-IDF Keywords:\n",
      "['amazing', 'bad', 'banking', 'dash', 'dash super', 'developer', 'easy', 'easy use', 'excellent', 'experience', 'fast', 'feature', 'fix', 'good', 'great', 'like', 'money', 'need', 'nice', 'option', 'super', 'thank', 'time', 'transaction', 'transfer', 'update', 'use', 'user', 'work', 'wow'] \n",
      "\n",
      "üè¶ CBE Top 20 Noun Phrases:\n",
      "['work', 'money', 'easy use', 'love', 'good', 'good job', 'life', 'improvement', 'screenshot feature', 'screenshot', 'birr', 'country', 'kenya nigeria south africa', 'physically old security layer', 'fraud attempt', 'space', 'abib', 'eng ida key fete', 'safety', 'facilitate client'] \n",
      "\n",
      "üè¶ CBE Theme Distribution:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "themes",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "cde070aa-8d09-4732-a297-e966b0616b52",
       "rows": [
        [
         "Other",
         "227"
        ],
        [
         "Concise Feedback",
         "135"
        ],
        [
         "Performance",
         "17"
        ],
        [
         "Functionality",
         "10"
        ],
        [
         "Connection Issues",
         "9"
        ],
        [
         "Feature Requests",
         "7"
        ],
        [
         "Stability & Bugs",
         "7"
        ],
        [
         "Security & Trust",
         "5"
        ],
        [
         "Usability",
         "1"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 9
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>themes</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Concise Feedback</th>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Performance</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Functionality</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Connection Issues</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature Requests</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stability &amp; Bugs</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Security &amp; Trust</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Usability</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   count\n",
       "themes                  \n",
       "Other                227\n",
       "Concise Feedback     135\n",
       "Performance           17\n",
       "Functionality         10\n",
       "Connection Issues      9\n",
       "Feature Requests       7\n",
       "Stability & Bugs       7\n",
       "Security & Trust       5\n",
       "Usability              1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üè¶ BOA Top 30 TF-IDF Keywords:\n",
      "['amazing', 'bad', 'banking', 'dash', 'dash super', 'developer', 'easy', 'easy use', 'excellent', 'experience', 'fast', 'feature', 'fix', 'good', 'great', 'like', 'money', 'need', 'nice', 'option', 'super', 'thank', 'time', 'transaction', 'transfer', 'update', 'use', 'user', 'work', 'wow'] \n",
      "\n",
      "üè¶ BOA Top 20 Noun Phrases:\n",
      "['work', 'boa', 'money', 'developer option', 'love', 'guy', 'long time', 'time', 'great boa', 'transaction', 'download', 'device', 'crash', 'problem', 'boa system', 'long piss fix problem', 'half', 'kind social experiment test patience build sleep', 'different career path', 'open android'] \n",
      "\n",
      "üè¶ BOA Theme Distribution:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "themes",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "3e44cc97-66cf-41e2-823a-710407a9b53e",
       "rows": [
        [
         "Other",
         "227"
        ],
        [
         "Concise Feedback",
         "115"
        ],
        [
         "Performance",
         "23"
        ],
        [
         "Stability & Bugs",
         "20"
        ],
        [
         "Functionality",
         "19"
        ],
        [
         "Account Access",
         "11"
        ],
        [
         "Feature Requests",
         "4"
        ],
        [
         "Notifications",
         "2"
        ],
        [
         "Usability",
         "2"
        ],
        [
         "Security & Trust",
         "2"
        ],
        [
         "Connection Issues",
         "2"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 11
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>themes</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Concise Feedback</th>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Performance</th>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stability &amp; Bugs</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Functionality</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Account Access</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature Requests</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Notifications</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Usability</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Security &amp; Trust</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Connection Issues</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   count\n",
       "themes                  \n",
       "Other                227\n",
       "Concise Feedback     115\n",
       "Performance           23\n",
       "Stability & Bugs      20\n",
       "Functionality         19\n",
       "Account Access        11\n",
       "Feature Requests       4\n",
       "Notifications          2\n",
       "Usability              2\n",
       "Security & Trust       2\n",
       "Connection Issues      2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üè¶ Dashen Top 30 TF-IDF Keywords:\n",
      "['amazing', 'bad', 'banking', 'dash', 'dash super', 'developer', 'easy', 'easy use', 'excellent', 'experience', 'fast', 'feature', 'fix', 'good', 'great', 'like', 'money', 'need', 'nice', 'option', 'super', 'thank', 'time', 'transaction', 'transfer', 'update', 'use', 'user', 'work', 'wow'] \n",
      "\n",
      "üè¶ Dashen Top 20 Noun Phrases:\n",
      "['transaction', 'payment', 'money', 'life', 'love', 'waw', 'banking', 'customer', 'ethiopia innovation', 'seamless shopping experience', 'expectation marketplace', 'new update commerce section', 'balance transfer money', 'spending', 'fast easy use', 'tel birr mesa', 'work', 'gad', 'real life changer', 'simple robust feature'] \n",
      "\n",
      "üè¶ Dashen Theme Distribution:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "themes",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "9419a062-a4da-4972-a725-c2ddc15086c5",
       "rows": [
        [
         "Other",
         "201"
        ],
        [
         "Concise Feedback",
         "104"
        ],
        [
         "Performance",
         "63"
        ],
        [
         "Functionality",
         "49"
        ],
        [
         "Security & Trust",
         "21"
        ],
        [
         "Account Access",
         "13"
        ],
        [
         "Feature Requests",
         "11"
        ],
        [
         "Stability & Bugs",
         "7"
        ],
        [
         "Notifications",
         "1"
        ],
        [
         "Connection Issues",
         "1"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>themes</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Concise Feedback</th>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Performance</th>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Functionality</th>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Security &amp; Trust</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Account Access</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature Requests</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stability &amp; Bugs</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Notifications</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Connection Issues</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   count\n",
       "themes                  \n",
       "Other                201\n",
       "Concise Feedback     104\n",
       "Performance           63\n",
       "Functionality         49\n",
       "Security & Trust      21\n",
       "Account Access        13\n",
       "Feature Requests      11\n",
       "Stability & Bugs       7\n",
       "Notifications          1\n",
       "Connection Issues      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# üóùÔ∏è Keyword, Keyphrase & Theme Extraction (Using Enriched Splits)\n",
    "# ------------------------------------------------------------------------------\n",
    "from src.nlp.keyword_theme_extractor import (\n",
    "    KeywordExtractor,\n",
    "    KeyPhraseExtractor,\n",
    "    ThemeExtractor,\n",
    ")\n",
    "from src.nlp.stopwords import COMBINED_STOPWORDS\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import spacy  # need full pipeline for noun_chunks\n",
    "\n",
    "# 1Ô∏è‚É£ Re-split the ENRICHED DataFrame so each has `normalized_review`\n",
    "df_cbe = df_enriched[df_enriched[\"bank\"] == \"CBE\"].reset_index(drop=True)\n",
    "df_boa = df_enriched[df_enriched[\"bank\"] == \"BOA\"].reset_index(drop=True)\n",
    "df_dashen = df_enriched[df_enriched[\"bank\"] == \"Dashen\"].reset_index(drop=True)\n",
    "\n",
    "# 2Ô∏è‚É£ Prepare the text corpora from those enriched splits\n",
    "texts_all = df_enriched[\"normalized_review\"].dropna().tolist()\n",
    "texts_cbe = df_cbe[\"normalized_review\"].dropna().tolist()\n",
    "texts_boa = df_boa[\"normalized_review\"].dropna().tolist()\n",
    "texts_dashen = df_dashen[\"normalized_review\"].dropna().tolist()\n",
    "\n",
    "# 3Ô∏è‚É£ Initialize your extractors using the centralized stopword set\n",
    "kw_extractor = KeywordExtractor(stopwords=list(COMBINED_STOPWORDS), max_features=30)\n",
    "phrase_extractor = KeyPhraseExtractor(stopwords=list(COMBINED_STOPWORDS))\n",
    "\n",
    "# üîß Reload the spaCy pipeline with parser enabled for noun_chunks\n",
    "phrase_extractor.nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# 4Ô∏è‚É£ Define per-bank theme seeds\n",
    "seed_map = {\n",
    "    \"CBE\": {\n",
    "        \"Concise Feedback\": [\"good\",\"bad\",\"fine\",\"ok\"],\n",
    "        \"Account Access\":   [\"login\",\"otp\",\"password\",\"pin\"],\n",
    "        \"Connection Issues\":[\"network\",\"offline\",\"timeout\",\"disconnect\"],\n",
    "        \"Usability\":        [\"hard to use\",\"navigate\",\"layout\",\"ux\"],\n",
    "        \"Performance\":      [\"slow\",\"lag\",\"speed\",\"delay\",\"fast\"],\n",
    "        \"Functionality\":    [\"feature\",\"cannot\",\"unable\",\"doesn't\",\"option\"],\n",
    "        \"Feature Requests\":[\"should have\",\"wish\",\"add\",\"feature request\"],\n",
    "        \"Security & Trust\":[\"secure\",\"fraud\",\"trust\",\"encryption\",\"leak\"],\n",
    "        \"Notifications\":    [\"alert\",\"notification\",\"push\",\"reminder\",\"email\"],\n",
    "        \"Stability & Bugs\": [\"crash\",\"freeze\",\"error\",\"bug\",\"exception\"],\n",
    "    },\n",
    "    \"BOA\": {\n",
    "        \"Concise Feedback\": [\"good\",\"bad\",\"fine\",\"ok\"],\n",
    "        \"Account Access\":   [\"login\",\"otp\",\"password\",\"pin\"],\n",
    "        \"Connection Issues\":[\"network\",\"offline\",\"timeout\",\"disconnect\"],\n",
    "        \"Usability\":        [\"hard to use\",\"navigate\",\"layout\",\"ux\"],\n",
    "        \"Performance\":      [\"slow\",\"lag\",\"speed\",\"delay\",\"fast\"],\n",
    "        \"Functionality\":    [\"feature\",\"cannot\",\"unable\",\"doesn't\",\"option\"],\n",
    "        \"Feature Requests\":[\"should have\",\"wish\",\"add\",\"feature request\"],\n",
    "        \"Security & Trust\":[\"secure\",\"fraud\",\"trust\",\"encryption\",\"leak\"],\n",
    "        \"Notifications\":    [\"alert\",\"notification\",\"push\",\"reminder\",\"email\"],\n",
    "        \"Stability & Bugs\": [\"crash\",\"freeze\",\"error\",\"bug\",\"exception\"],\n",
    "    },\n",
    "    \"Dashen\": {\n",
    "        \"Concise Feedback\": [\"good\",\"bad\",\"fine\",\"ok\"],\n",
    "        \"Account Access\":   [\"login\",\"otp\",\"password\",\"pin\"],\n",
    "        \"Connection Issues\":[\"network\",\"offline\",\"timeout\",\"disconnect\"],\n",
    "        \"Usability\":        [\"hard to use\",\"navigate\",\"layout\",\"ux\"],\n",
    "        \"Performance\":      [\"slow\",\"lag\",\"speed\",\"delay\",\"fast\"],\n",
    "        \"Functionality\":    [\"feature\",\"cannot\",\"unable\",\"doesn't\",\"option\"],\n",
    "        \"Feature Requests\":[\"should have\",\"wish\",\"add\",\"feature request\"],\n",
    "        \"Security & Trust\":[\"secure\",\"fraud\",\"trust\",\"encryption\",\"leak\"],\n",
    "        \"Notifications\":    [\"alert\",\"notification\",\"push\",\"reminder\",\"email\"],\n",
    "        \"Stability & Bugs\": [\"crash\",\"freeze\",\"error\",\"bug\",\"exception\"],\n",
    "    }\n",
    "}\n",
    "theme_extractor = ThemeExtractor(seed_map=seed_map)\n",
    "\n",
    "# 5Ô∏è‚É£ Extract & display GLOBAL results\n",
    "global_keywords = kw_extractor.extract_keywords(texts_all)\n",
    "global_phrases = phrase_extractor.extract_top_phrases(texts_all, top_n=20)\n",
    "df_all_tagged = theme_extractor.tag_corpus(df_enriched)\n",
    "\n",
    "print(\"üîë Global Top 30 TF-IDF Keywords:\")\n",
    "print(global_keywords, \"\\n\")\n",
    "\n",
    "print(\"üß† Global Top 20 Noun Phrases:\")\n",
    "print(global_phrases, \"\\n\")\n",
    "\n",
    "print(\"üìä Global Theme Distribution:\")\n",
    "display(df_all_tagged[\"themes\"].explode().value_counts().to_frame(\"count\"))\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# >>> Write out the fully enriched + themed CSV for downstream visualization\n",
    "df_all_tagged.to_csv(\"data/outputs/reviews_with_sentiment_themes.csv\", index=False)\n",
    "print(\"‚úÖ Saved enriched themes to data/outputs/reviews_with_sentiment_themes.csv\")\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "# 6Ô∏è‚É£ Extract & display PER-BANK results using enriched splits\n",
    "for bank, texts, df_bank in [\n",
    "    (\"CBE\", texts_cbe, df_cbe),\n",
    "    (\"BOA\", texts_boa, df_boa),\n",
    "    (\"Dashen\", texts_dashen, df_dashen),\n",
    "]:\n",
    "    print(f\"\\nüè¶ {bank} Top 30 TF-IDF Keywords:\")\n",
    "    print(kw_extractor.extract_keywords(texts), \"\\n\")\n",
    "\n",
    "    print(f\"üè¶ {bank} Top 20 Noun Phrases:\")\n",
    "    print(phrase_extractor.extract_top_phrases(texts, top_n=20), \"\\n\")\n",
    "\n",
    "    df_bank_tagged = theme_extractor.tag_corpus(df_bank)\n",
    "    print(f\"üè¶ {bank} Theme Distribution:\")\n",
    "    display(df_bank_tagged[\"themes\"].explode().value_counts().to_frame(\"count\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "customer-ux-challenge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
