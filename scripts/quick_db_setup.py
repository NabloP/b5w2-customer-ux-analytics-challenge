#!/usr/bin/env python3
"""
quick_db_setup.py

One-off script to stand up your Oracle schema and load enriched review data.
Drops existing tables, creates new ones, seeds themes, and upserts CSV data.
"""

import os
import sys
import logging
import csv
import oracledb

# â”€â”€â”€ 1. Fix Python path so we can locate data folder â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
script_dir = os.path.dirname(os.path.abspath(__file__))  # .../project/scripts
project_root = os.path.dirname(script_dir)  # .../project
data_dir = os.path.join(project_root, "data", "outputs")  # .../project/data/outputs

# â”€â”€â”€ 2. Inline your seed_map â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
seed_map = {
    "CBE": {
        "Concise Feedback": ["good", "bad", "fine", "ok"],
        "Account Access": ["login", "otp", "password", "pin"],
        "Connection Issues": ["network", "offline", "timeout", "disconnect"],
        "Usability": ["hard to use", "navigate", "layout", "ux"],
        "Performance": ["slow", "lag", "speed", "delay", "fast"],
        "Functionality": ["feature", "cannot", "unable", "doesn't", "option"],
        "Feature Requests": ["should have", "wish", "add", "feature request"],
        "Security & Trust": ["secure", "fraud", "trust", "encryption", "leak"],
        "Notifications": ["alert", "notification", "push", "reminder", "email"],
        "Stability & Bugs": ["crash", "freeze", "error", "bug", "exception"],
    },
    "BOA": {
        # paste your BOA theme definitions here...
    },
    "Dashen": {
        # paste your Dashen theme definitions here...
    },
}

# â”€â”€â”€ 3. Hard-coded Oracle credentials & DSN â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
USER = "sysdba"
PASS = "cofee@12AM"
DSN = "localhost:1521/XEPDB1"

# â”€â”€â”€ 4. Logging setup â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
logging.basicConfig(level=logging.INFO, format="%(asctime)s %(levelname)s %(message)s")
logger = logging.getLogger("quick_db_setup")


def main():
    # Connect to Oracle
    conn = oracledb.connect(user=USER, password=PASS, dsn=DSN)
    cur = conn.cursor()
    logger.info("Connected to Oracle as %s", conn.username)

    # A) Drop tables if they exist
    for tbl in [
        "review_theme_map",
        "review_themes",
        "reviews_enriched",
        "reviews_raw",
        "reviews",
        "banks",
    ]:
        try:
            cur.execute(f"DROP TABLE {tbl} CASCADE CONSTRAINTS")
            logger.info("Dropped table %s", tbl)
        except oracledb.DatabaseError:
            pass

    # B) Create schema
    DDL = {
        "banks": """
            CREATE TABLE banks (
              bank_id   NUMBER GENERATED BY DEFAULT ON NULL AS IDENTITY PRIMARY KEY,
              bank_code VARCHAR2(50) NOT NULL UNIQUE,
              bank_name VARCHAR2(200),
              created_at TIMESTAMP DEFAULT SYSTIMESTAMP
            )
        """,
        "reviews": """
            CREATE TABLE reviews (
              review_pk   NUMBER GENERATED ALWAYS AS IDENTITY PRIMARY KEY,
              review_id   VARCHAR2(100) NOT NULL UNIQUE,
              bank_id     NUMBER NOT NULL,
              rating      NUMBER(2,1),
              review_date DATE,
              source      VARCHAR2(100),
              user_name   VARCHAR2(200),
              user_image  VARCHAR2(500),
              app_version VARCHAR2(50),
              thumbs_up   NUMBER,
              CONSTRAINT fk_reviews_bank FOREIGN KEY (bank_id) REFERENCES banks(bank_id)
            )
        """,
        "reviews_raw": """
            CREATE TABLE reviews_raw (
              review_pk     NUMBER PRIMARY KEY,
              raw_content   CLOB,
              replied_at    TIMESTAMP,
              reply_content CLOB,
              CONSTRAINT fk_raw_review FOREIGN KEY (review_pk) REFERENCES reviews(review_pk)
            )
        """,
        "reviews_enriched": """
            CREATE TABLE reviews_enriched (
              review_pk         NUMBER PRIMARY KEY,
              normalized_review CLOB,
              bert_score        NUMBER,
              vader_score       NUMBER,
              textblob_score    NUMBER,
              ensemble_score    NUMBER,
              label             VARCHAR2(50),
              uncertainty       NUMBER,
              rule_label        VARCHAR2(50),
              flag              CHAR(1) CHECK (flag IN ('0','1')),
              CONSTRAINT fk_enriched_review FOREIGN KEY (review_pk) REFERENCES reviews(review_pk)
            )
        """,
        "review_themes": """
            CREATE TABLE review_themes (
              theme_id    NUMBER GENERATED BY DEFAULT ON NULL AS IDENTITY PRIMARY KEY,
              theme_name  VARCHAR2(200) UNIQUE,
              description VARCHAR2(1000)
            )
        """,
        "review_theme_map": """
            CREATE TABLE review_theme_map (
              review_pk NUMBER,
              theme_id  NUMBER,
              PRIMARY KEY (review_pk, theme_id),
              CONSTRAINT fk_rtm_review FOREIGN KEY (review_pk) REFERENCES reviews(review_pk),
              CONSTRAINT fk_rtm_theme  FOREIGN KEY (theme_id)  REFERENCES review_themes(theme_id)
            )
        """,
    }
    for name, ddl in DDL.items():
        cur.execute(ddl)
        logger.info("Created table %s", name)

    # C) Seed themes
    for theme_name, desc in seed_map.items():
        cur.execute(
            """
            MERGE INTO review_themes t
            USING (SELECT :nm AS theme_name FROM dual) src
            ON (t.theme_name = src.theme_name)
            WHEN NOT MATCHED THEN
              INSERT (theme_name, description) VALUES (src.theme_name, :desc)
        """,
            {"nm": theme_name, "desc": desc},
        )
    conn.commit()
    logger.info("Seeded %d themes", len(seed_map))

    # D) Bulk-upsert enriched_reviews.csv
    merge_sql = """
        MERGE INTO reviews_enriched tgt
        USING (
          SELECT r.review_pk rk FROM reviews r WHERE r.review_id = :rid
        ) src
        ON (tgt.review_pk = src.rk)
        WHEN MATCHED THEN
          UPDATE SET
            normalized_review = :nrm,
            bert_score        = :b,
            vader_score       = :v,
            textblob_score    = :t,
            ensemble_score    = :e,
            label             = :lab,
            uncertainty       = :u,
            rule_label        = :rl,
            flag              = :f
        WHEN NOT MATCHED THEN
          INSERT (
            review_pk, normalized_review, bert_score, vader_score,
            textblob_score, ensemble_score, label, uncertainty, rule_label, flag
          )
          VALUES (
            src.rk, :nrm, :b, :v,
            :t, :e, :lab, :u, :rl, :f
          )
    """
    inserted = updated = 0
    csv_path = os.path.join(data_dir, "enriched_reviews.csv")
    with open(csv_path, encoding="utf-8") as f:
        for row in csv.DictReader(f):
            params = {
                "rid": row["reviewID"],
                "nrm": row["normalized_review"],
                "b": float(row["bert"]),
                "v": float(row["vader"]),
                "t": float(row["textblob"]),
                "e": float(row["ensemble"]),
                "lab": row["label"],
                "u": float(row["uncertainty"]),
                "rl": row["rule_label"],
                "f": "1" if row["flag"].lower() in ("1", "true") else "0",
            }
            cur.execute(merge_sql, params)
            if cur.rowcount == 1:
                inserted += 1
            else:
                updated += 1
    conn.commit()
    logger.info("Upserted enriched reviews: %d inserted, %d updated", inserted, updated)

    # E) Cleanup
    cur.close()
    conn.close()
    logger.info("ðŸŽ‰ All done: schema created and data loaded.")


if __name__ == "__main__":
    main()
